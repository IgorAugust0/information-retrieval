{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução a Web Scraping - 07/11/2023\n",
        "\n",
        "Organização e Recuperação da Informação\n",
        "\n",
        "Professor: Wendel Melo\n",
        "\n",
        "\n",
        "Referência\n",
        "\n",
        "[1] Ryan Mitchell, Web scraping com Python. O'Relly, 2ª edição, 2019;\n",
        "\n",
        "Links para a aula de hoje:\n",
        "\n",
        "* https://viacep.com.br\n",
        "* http://www.pythonscraping.com/pages/page1.html\n",
        "* https://www.pythonscraping.com/pages/warandpeace.html"
      ],
      "metadata": {
        "id": "faeCcCn0oWY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exemplo: API e JSON\n",
        "\n",
        "Vamos fazer um programa para descobrir um determinado cep usando API online do viacep ( https://viacep.com.br )"
      ],
      "metadata": {
        "id": "f0MUni90o_AZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnCeLMzvmx0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7bdfc5-990a-4731-c3f2-792b58917dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dados:  {'cep': '38408-100', 'logradouro': 'Avenida João Naves de Ávila', 'complemento': 'de 1260 a 3630 - lado par', 'bairro': 'Saraiva', 'localidade': 'Uberlândia', 'uf': 'MG', 'ibge': '3170206', 'gia': '', 'ddd': '34', 'siafi': '5403'}\n",
            "Logradouro:  Avenida João Naves de Ávila\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "cep = \"38408100\"\n",
        "\n",
        "resposta = requests.get( f\"https://viacep.com.br/ws/{cep}/json/\" )\n",
        "if resposta.status_code == 200:  #testa se a requisição https foi respondida com sucesso\n",
        "  dados = resposta.json()\n",
        "  print('dados: ', dados)\n",
        "  print( 'Logradouro: ', dados['logradouro'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existem API's para absolutamente tudo na WEB!\n",
        "\n",
        "Uma lista (nada exaustiva) pode ser conferida aqui:\n",
        "\n",
        "https://www.linkedin.com/pulse/80-apis-para-você-usar-nos-seus-projetos-e-praticar-leticia-coelho/?originalSubdomain=pt"
      ],
      "metadata": {
        "id": "FxmMVDJwg7nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução a WEB Scraping com BeautifulSoup\n",
        "\n",
        "Web scraping é o ato de usar ferramenta para coletar informações da internet sem o uso de uma API.\n",
        "\n",
        "Para realizar a instalação do beautiful soup 4:\n",
        "\n",
        "* pip3 install -U beautifulsoup4\n",
        "* pip install -U beautifulsoup4\n",
        "* py -m pip install -U beautifulsoup4\n",
        "* python -m pip install -U beautifulsoup4\n",
        "* python3 -m pip install -U beautifulsoup4"
      ],
      "metadata": {
        "id": "7HKkqINApQls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# código que acessa o endereço https://www.pythonscraping.com/pages/page1.html\n",
        "#e pega o conteúdo entre as tags <h1> e </h1> (título)\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = urlopen( r\"https://www.pythonscraping.com/pages/page1.html\")\n",
        "conteudo = html.read()\n",
        "\n",
        "bs = BeautifulSoup(conteudo, \"html.parser\")\n",
        "\n",
        "print( bs.h1 ) # retorna o primeiro elemento h1 da página"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP89bJNx6pYW",
        "outputId": "647b115d-2dc0-4752-e526-8b4d86e701f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = bs.h1\n",
        "h1.get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vRC1Xm369jVZ",
        "outputId": "ec3e3d10-5739-4fe1-9503-ec147ff0bc13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'An Interesting Title'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uma coisa que pode ocorrer é obter algum tipo de erro no acesso\n",
        "from requests.models import HTTPError\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "try:\n",
        "  html = urlopen( r\"https://www.pythonscraping.com/pages/page1.html\")\n",
        "except HTTPError as e:\n",
        "  print(e)\n",
        "else:\n",
        "  conteudo = html.read()\n",
        "\n",
        "bs = BeautifulSoup(conteudo, \"html.parser\")\n",
        "\n",
        "print( bs.h1 ) # retorna o primeiro elemento h1 da página"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBE-NeC498Km",
        "outputId": "41372ee5-65a0-41a2-dea5-22056f86f3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<h1>An Interesting Title</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# podemos percorrer os subelementos de um elemento com um laço for\n",
        "for elemento in bs.body:     #percorre os subelementos de body\n",
        "  print( 'elemento:', elemento )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk3vPfFP_Gj0",
        "outputId": "bf7a5b37-2473-4237-c0b6-0f047daca548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elemento: \n",
            "\n",
            "elemento: <h1>An Interesting Title</h1>\n",
            "elemento: \n",
            "\n",
            "elemento: <div>\n",
            "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
            "</div>\n",
            "elemento: \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos fazer um código para acessar a página:\n",
        "\n",
        "https://www.pythonscraping.com/pages/warandpeace.html\n",
        "\n",
        "e obter os nomes próprios.\n",
        "\n",
        "Analisando o código HTML, percebemos que os nomes próprios sempre estão contigos em tags span com a classe green. Podemos então usar bs para obter uma lista com todos os nomes usando o método find_all"
      ],
      "metadata": {
        "id": "pcGl2Q_9BJx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = urlopen( r\"https://www.pythonscraping.com/pages/warandpeace.html\")\n",
        "conteudo = html.read()\n",
        "\n",
        "bs = BeautifulSoup(conteudo, \"html.parser\")\n",
        "\n",
        "tagsNomes = bs.find_all( 'span', {'class':'green'} )\n",
        "nomes = [ tag.get_text() for tag in tagsNomes ]\n",
        "print( nomes )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM3v2MLLBMxT",
        "outputId": "53e3d7cd-ab7e-41db-a438-5b28647d4be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Anna\\nPavlovna Scherer', 'Empress Marya\\nFedorovna', 'Prince Vasili Kuragin', 'Anna Pavlovna', 'St. Petersburg', 'the prince', 'Anna Pavlovna', 'Anna Pavlovna', 'the prince', 'the prince', 'the prince', 'Prince Vasili', 'Anna Pavlovna', 'Anna Pavlovna', 'the prince', 'Wintzingerode', 'King of Prussia', 'le Vicomte de Mortemart', 'Montmorencys', 'Rohans', 'Abbe Morio', 'the Emperor', 'the prince', 'Prince Vasili', 'Dowager Empress Marya Fedorovna', 'the baron', 'Anna Pavlovna', 'the Empress', 'the Empress', \"Anna Pavlovna's\", 'Her Majesty', 'Baron\\nFunke', 'The prince', 'Anna\\nPavlovna', 'the Empress', 'The prince', 'Anatole', 'the prince', 'The prince', 'Anna\\nPavlovna', 'Anna Pavlovna']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#podemos fazer a busca a partir de um elemento específico\n",
        "#procura pelas tags span da classe green dentro da primeira div sob o body.\n",
        "bs.body.div.find_all( 'span', {'class':'green'} )\n",
        "nomes = [ tag.get_text() for tag in tagsNomes ]\n",
        "print( nomes )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcKkpNxXDBSa",
        "outputId": "21372898-5dba-4cd2-bb63-b1ad5c03e3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Anna\\nPavlovna Scherer', 'Empress Marya\\nFedorovna', 'Prince Vasili Kuragin', 'Anna Pavlovna', 'St. Petersburg', 'the prince', 'Anna Pavlovna', 'Anna Pavlovna', 'the prince', 'the prince', 'the prince', 'Prince Vasili', 'Anna Pavlovna', 'Anna Pavlovna', 'the prince', 'Wintzingerode', 'King of Prussia', 'le Vicomte de Mortemart', 'Montmorencys', 'Rohans', 'Abbe Morio', 'the Emperor', 'the prince', 'Prince Vasili', 'Dowager Empress Marya Fedorovna', 'the baron', 'Anna Pavlovna', 'the Empress', 'the Empress', \"Anna Pavlovna's\", 'Her Majesty', 'Baron\\nFunke', 'The prince', 'Anna\\nPavlovna', 'the Empress', 'The prince', 'Anatole', 'the prince', 'The prince', 'Anna\\nPavlovna', 'Anna Pavlovna']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#podemos pasar uma lista de atributos para o método find\n",
        "bs.find_all( ['h1', 'div'] )  #encntra todas as tags h1 e todas as tags div"
      ],
      "metadata": {
        "id": "p9Z8G2sHD5Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#podemos por exemplo, acessar as tags span das classes 'green' e 'red'\n",
        "bs.find_all( 'span', {'class': ['green', 'red']} )"
      ],
      "metadata": {
        "id": "wPVlD9YgETEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#podemos acessar atributos das tags\n",
        "\n",
        "#o método find retorna o primeiro elemento encontrado com as características especificadas\n",
        "div1 = bs.find('div')\n",
        "div1['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RcF8zNCCEyUK",
        "outputId": "4c3d61f3-2bec-4e81-d9ca-0a4301d32760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'text'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div1.attrs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFU9N53DFcg2",
        "outputId": "4a1d788e-a704-4c91-8fa2-0d8118596bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'text'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "div1.get_next"
      ],
      "metadata": {
        "id": "f-B-nPX5FiJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}